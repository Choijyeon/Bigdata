{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [+] SparkConf, SparkContext 임포트\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    [+] SparkConf 객체 생성 및 설정\n",
    "    - setMaster(), 마스터 노드 위치: \"local\"\n",
    "    - 앱이름: \"transformations_actions\"\n",
    "\"\"\"\n",
    "\n",
    "conf = SparkConf().setMaster('local').setAppName('transformation_actions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=transformation_actions, master=local) created by __init__ at <ipython-input-3-c9cee7789c39>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c9cee7789c39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# [+] SparkContext 객체 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                     \u001b[1;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    351\u001b[0m                         \u001b[1;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                         \u001b[1;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=transformation_actions, master=local) created by __init__ at <ipython-input-3-c9cee7789c39>:2 "
     ]
    }
   ],
   "source": [
    "# [+] SparkContext 객체 생성\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.driver.host', 'LAPTOP-K5S3UUQF'),\n",
       " ('spark.driver.port', '62959'),\n",
       " ('spark.app.id', 'local-1654695735930'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.startTime', '1654695732413'),\n",
       " ('spark.app.name', 'transformation_actions'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark 전체 설정 값 확인\n",
    "sc.getConf().getAll()\n",
    "\n",
    "# getConf() : SparkConf()객체인 conf가 return\n",
    "# getAll() : Spakr에 설정된 모든 값 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=transformation_actions, master=local) created by __init__ at <ipython-input-3-c9cee7789c39>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-48aa4f593e91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# SpackContext 객체 하나 더 생성하기(과연?)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 오류 발생함 -> Cannot run multiple SparkContexts at once (여러 개의 spark context설정할 수 없다)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                     \u001b[1;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    351\u001b[0m                         \u001b[1;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                         \u001b[1;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=transformation_actions, master=local) created by __init__ at <ipython-input-3-c9cee7789c39>:2 "
     ]
    }
   ],
   "source": [
    "# SpackContext 객체 하나 더 생성하기(과연?)\n",
    "sc = SparkContext(conf=conf)\n",
    "# 오류 발생함 -> Cannot run multiple SparkContexts at once (여러 개의 spark context설정할 수 없다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkContext는 프로그램 내에서 하나의 객체만 생성할 수 있다. (= Singleton 패턴)\n",
    "sc.stop()       # SparkContext 객체 해제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 생성하기\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 Actions 함수 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    [+] List로부터 RDD 객체 생성\n",
    "    - SparkContext.parallelize()\n",
    "    - 리스트 값: \n",
    "    \"짜장면\", \"마라탕\", \"짬뽕\", \n",
    "    \"떡볶이\", \"쌀국수\", \"짬뽕\", \n",
    "    \"짜장면\", \"짜장면\", \"짜장면\", \n",
    "    \"라면\", \"우동\", \"라면\"\n",
    "\"\"\"\n",
    "lst = [\"짜장면\", \"마라탕\", \"짬뽕\", \n",
    "    \"떡볶이\", \"쌀국수\", \"짬뽕\", \n",
    "    \"짜장면\", \"짜장면\", \"짜장면\", \n",
    "    \"라면\", \"우동\", \"라면\"]\n",
    "\n",
    "foods = sc.parallelize(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕', '떡볶이', '쌀국수', '짬뽕', '짜장면', '짜장면', '짜장면', '라면', '우동', '라면']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [+] foods RDD 내용 출력\n",
    "foods.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'짜장면': 4,\n",
       "             '마라탕': 1,\n",
       "             '짬뽕': 2,\n",
       "             '떡볶이': 1,\n",
       "             '쌀국수': 1,\n",
       "             '라면': 2,\n",
       "             '우동': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [+] foods RDD 원소 값 별로 카운팅\n",
    "foods.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take(n): 처음 n개의 원소를 출력\n",
    "foods.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕', '떡볶이', '쌀국수']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foods.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'짜장면'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first(): 첫 번째 값을 출력\n",
    "foods.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count(): 원소 갯수 출력(중복된 원소 포함)\n",
    "foods.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕', '떡볶이', '쌀국수', '라면', '우동']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    distinct(): unique한 원소로 구성된 RDD 생성\n",
    "    - distinct() 자체는 transformation 이므로, collect()와 같은 action 을 결합하여 사용\n",
    "\"\"\"\n",
    "\n",
    "foods.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    foreach(): RDD 원소를 하나씩 꺼내서 함수 연산을 적용\n",
    "    - Worker node 에서 실행되기 때문에 Driver Program 에서 결과를 볼 수 없음\n",
    "    - Worker node 에서 따로 실행할 함수(예: 로깅)들을 적용할 때 사용\n",
    "\"\"\"\n",
    "\n",
    "foods.foreach(lambda x: print(x)) \n",
    "# print 보이지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 Transformations 함수 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[13] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformations 은 지연 실행된다.\n",
    "sc.parallelize([1, 2, 3]).map(lambda x: x + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actions 를 만나면 즉시 실행된다.\n",
    "sc.parallelize([1, 2, 3]).map(lambda x: x + 2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1, 2, 3]).map(lambda x: x * 2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\n",
    "    \"그린 북\",\n",
    "    \"매트릭스\",\n",
    "    \"토이 스토리\",\n",
    "    \"캐스트 어웨이\",\n",
    "    \"포드 V 페라리\",\n",
    "    \"보헤미안 랩소디\",\n",
    "    \"빽 투 더 퓨처\",\n",
    "    \"반지의 제왕\",\n",
    "    \"죽은 시인의 사회\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [+] 리스트(movies) -> RDD 객체(moviesRDD) 생성\n",
    "moviesRDD = sc.parallelize(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그린 북',\n",
       " '매트릭스',\n",
       " '토이 스토리',\n",
       " '캐스트 어웨이',\n",
       " '포드 V 페라리',\n",
       " '보헤미안 랩소디',\n",
       " '빽 투 더 퓨처',\n",
       " '반지의 제왕',\n",
       " '죽은 시인의 사회']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 단위로 쪼개서 보기\n",
    "# map :  원소 개수 유지(one-to-one) -> movieRDD에 적용하면 ['그린','북'] 이런 식으로 나올 것\n",
    "# flatMap : 원소 개수 증가(one-to-many transformation)\n",
    "flatMovies = moviesRDD.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그린',\n",
       " '북',\n",
       " '매트릭스',\n",
       " '토이',\n",
       " '스토리',\n",
       " '캐스트',\n",
       " '어웨이',\n",
       " '포드',\n",
       " 'V',\n",
       " '페라리',\n",
       " '보헤미안',\n",
       " '랩소디',\n",
       " '빽',\n",
       " '투',\n",
       " '더',\n",
       " '퓨처',\n",
       " '반지의',\n",
       " '제왕',\n",
       " '죽은',\n",
       " '시인의',\n",
       " '사회']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatMovies.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    [+] flatMovies 에서 '매트릭스'를 제외\n",
    "    - filter(lambda ...)\n",
    "    - 저장할 객체: filteredMovies\n",
    "\"\"\"\n",
    "\n",
    "filteredMovies = flatMovies.filter(lambda x: x != '매트릭스')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그린',\n",
       " '북',\n",
       " '토이',\n",
       " '스토리',\n",
       " '캐스트',\n",
       " '어웨이',\n",
       " '포드',\n",
       " 'V',\n",
       " '페라리',\n",
       " '보헤미안',\n",
       " '랩소디',\n",
       " '빽',\n",
       " '투',\n",
       " '더',\n",
       " '퓨처',\n",
       " '반지의',\n",
       " '제왕',\n",
       " '죽은',\n",
       " '시인의',\n",
       " '사회']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredMovies.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    집합 관련 transformations 연산\n",
    "\"\"\"\n",
    "\n",
    "num1 = sc.parallelize([1, 2, 3, 4])\n",
    "num2 = sc.parallelize([4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교집합(intersection) 구하기 -> num1기준으로 num2\n",
    "num1.intersection(num2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 합집합(union) 구하기\n",
    "num1.union(num2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차집합(substract) 구하기 -> 순서 바뀌어서 출력될 수 있음\n",
    "num1.subtract(num2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "numUnion = num1.union(num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numUnion.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 7, 7, 7, 10]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    sample(withReplacement, fraction): 원소를 랜덤 샘플링하여 새로운 RDD를 생성하는 narrow transformation\n",
    "    - withReplacement, bool[optional]: 중복 샘플링 허용 여부\n",
    "    - fraction, float[optional]: 샘플링 확률[0~1], 확률이므로 정확한 사이즈가 보장되지 않음(10개 원소 있다고 꼭 5개 나오는 게 아니라 각각의 원소에 대한 확률임)\n",
    "    - seed: 결과 재현(reproducibility)을 위한 설정 값\n",
    "\"\"\"\n",
    "\n",
    "numUnion.sample(True, 0.5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 9, 9, 10]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed 파라미터를 설정하면 동일한 결과를 반복적으로 얻을 수 있다.\n",
    "numUnion.sample(True, .5, seed=5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    groupBy(): 특정 기준(함수로 정의)으로 그룹핑을 수행하는 wide transformation\n",
    "\"\"\"\n",
    "\n",
    "foods = sc.parallelize([\"짜장면\", \"마라탕\", \"짬뽕\", \n",
    "                        \"떡볶이\", \"쌀국수\", \"짬뽕\", \n",
    "                        \"짜장면\", \"짜장면\", \"짜장면\",  \n",
    "                        \"라면\", \"우동\", \"라면\", \n",
    "                        \"치킨\", \"돈까스\", \"회\", \n",
    "                        \"햄버거\", \"피자\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  원소의 첫 번째 값을 기준으로 그룹핑\n",
    "foodsGroup = foods.groupBy(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜', <pyspark.resultiterable.ResultIterable at 0x2929cda6340>),\n",
       " ('마', <pyspark.resultiterable.ResultIterable at 0x2929cda6f40>),\n",
       " ('짬', <pyspark.resultiterable.ResultIterable at 0x2929cda6e50>),\n",
       " ('떡', <pyspark.resultiterable.ResultIterable at 0x2929ce72d00>),\n",
       " ('쌀', <pyspark.resultiterable.ResultIterable at 0x2929ce72070>),\n",
       " ('라', <pyspark.resultiterable.ResultIterable at 0x2929ce72280>),\n",
       " ('우', <pyspark.resultiterable.ResultIterable at 0x2929ce72a30>),\n",
       " ('치', <pyspark.resultiterable.ResultIterable at 0x2929ce729a0>),\n",
       " ('돈', <pyspark.resultiterable.ResultIterable at 0x2929ce72a90>),\n",
       " ('회', <pyspark.resultiterable.ResultIterable at 0x2929ce7d100>),\n",
       " ('햄', <pyspark.resultiterable.ResultIterable at 0x2929ce7d670>),\n",
       " ('피', <pyspark.resultiterable.ResultIterable at 0x2929ce7de50>)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foodsGroup.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect() 결과를 리스트 객체(res)에 저장\n",
    "res = foodsGroup.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜', <pyspark.resultiterable.ResultIterable at 0x2929ce7d9a0>),\n",
       " ('마', <pyspark.resultiterable.ResultIterable at 0x2928d5a5be0>),\n",
       " ('짬', <pyspark.resultiterable.ResultIterable at 0x2928d5a5100>),\n",
       " ('떡', <pyspark.resultiterable.ResultIterable at 0x2929cea5220>),\n",
       " ('쌀', <pyspark.resultiterable.ResultIterable at 0x2929cea50a0>),\n",
       " ('라', <pyspark.resultiterable.ResultIterable at 0x2929cea5c10>),\n",
       " ('우', <pyspark.resultiterable.ResultIterable at 0x2929cea5190>),\n",
       " ('치', <pyspark.resultiterable.ResultIterable at 0x2929cea53d0>),\n",
       " ('돈', <pyspark.resultiterable.ResultIterable at 0x2929cea5460>),\n",
       " ('회', <pyspark.resultiterable.ResultIterable at 0x2929cea5400>),\n",
       " ('햄', <pyspark.resultiterable.ResultIterable at 0x2929cea5610>),\n",
       " ('피', <pyspark.resultiterable.ResultIterable at 0x2929cea5e20>)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '짜장면', '짜장면', '짜장면']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResultIterable 객체는 list로 쉽게 변환 가능하다.\n",
    "list(res[0][1]) # resultiterable가져온 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "짜 ['짜장면', '짜장면', '짜장면', '짜장면']\n",
      "마 ['마라탕']\n",
      "짬 ['짬뽕', '짬뽕']\n",
      "떡 ['떡볶이']\n",
      "쌀 ['쌀국수']\n",
      "라 ['라면', '라면']\n",
      "우 ['우동']\n",
      "치 ['치킨']\n",
      "돈 ['돈까스']\n",
      "회 ['회']\n",
      "햄 ['햄버거']\n",
      "피 ['피자']\n"
     ]
    }
   ],
   "source": [
    "# for 문을 이용하여 구조적으로 결과를 출력\n",
    "for (k, v) in res:\n",
    "    print(k, list(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupBy()는 모드 연산과 같이 수학 연산에도 사용될 수 있다.\n",
    "nums = sc.parallelize([1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, <pyspark.resultiterable.ResultIterable at 0x2929ceadd30>),\n",
       " (0, <pyspark.resultiterable.ResultIterable at 0x2929ce7ddf0>)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.groupBy(lambda x: x % 2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [+] '1' 그룹에 해당되는 원소 리스트 출력하기\n",
    "list(nums.groupBy(lambda x: x % 2).collect()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [+] '0' 그룹에 해당되는 원소 리스트 출력하기\n",
    "list(nums.groupBy(lambda x: x % 2).collect()[1][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
